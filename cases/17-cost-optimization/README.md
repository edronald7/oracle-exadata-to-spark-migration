# Caso 17: Cost Optimization

**Criticidad**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (CR√çTICA en cloud)  
**Frecuencia**: An√°lisis semanal  

En cloud, el costo es preocupaci√≥n #1. Optimiza o quiebras el presupuesto.

---

## üìä D√≥nde se va el dinero

1. **Shuffle** (40%): Datos movi√©ndose entre nodos
2. **Spill to disk** (20%): Out of memory
3. **Small files** (15%): Miles de archivos peque√±os
4. **Compute idle** (15%): Clusters sin usar
5. **Storage** (10%): Datos duplicados/sin comprimir

---

## üí∞ Optimizaciones Cr√≠ticas

### 1. Evitar Shuffle Innecesario

```python
# ‚ùå BAD: Shuffle costoso (500GB)
df1 = large_fact.repartition(200)
df2 = df1.join(large_dim, 'key')  # Shuffle join
# Cost: $50/d√≠a

# ‚úÖ GOOD: Broadcast join (0 shuffle)
df2 = large_fact.join(broadcast(small_dim), 'key')
# Cost: $5/d√≠a
```

### 2. Compaction (Small Files)

```sql
-- ‚ùå BAD: 10,000 archivos de 1MB cada uno
-- Read performance: SLOW
-- Cost: Alto (muchos API calls)

-- ‚úÖ GOOD: 100 archivos de 100MB cada uno
OPTIMIZE customers_delta;
-- Consolida archivos

-- Resultado: 10x m√°s r√°pido, 50% menos costo
```

### 3. Partition Pruning

```python
# ‚ùå BAD: Escanea todo (1TB)
df = spark.read.parquet('s3://bucket/sales')
result = df.filter('date = '2026-01-12'')
# Cost: $10

# ‚úÖ GOOD: Solo lee partici√≥n necesaria (1GB)
df = spark.read.parquet('s3://bucket/sales/date=2026-01-12')
# Cost: $0.10 (100x m√°s barato)
```

### 4. Column Pruning

```python
# ‚ùå BAD: Lee 50 columnas
df = spark.read.parquet('data')
result = df.select('id', 'amount')
# Pero lee TODAS las columnas del disco

# ‚úÖ GOOD: Parquet columnar, solo lee 2 columnas
# Autom√°tico con Parquet
# 25x m√°s r√°pido, 25x m√°s barato
```

### 5. Spot/Preemptible Instances

```bash
# ‚ùå On-demand: $2/hora
# ‚úÖ Spot: $0.40/hora (80% descuento)

# AWS EMR con spot
--instance-type r5.4xlarge \\
--bid-price 0.50

# Ahorro: $12,000/a√±o por cluster
```

---

## üìä An√°lisis de Spark UI

```
Identificar bottlenecks:
1. Stage con shuffle writes alto ‚Üí Broadcast join
2. Tasks con spill to disk ‚Üí M√°s memoria
3. Skewed partitions ‚Üí Repartition
4. Muchos small tasks ‚Üí Coalesce
```

---

## üí° Quick Wins

| Optimizaci√≥n | Effort | Impacto | ROI |
|--------------|--------|---------|-----|
| Broadcast joins peque√±as dims | Bajo | 10x | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Spot instances | Bajo | 5x | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| OPTIMIZE/compaction | Medio | 3x | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Partition pruning fix | Bajo | 10x | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Column pruning (SELECT) | Bajo | 2x | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üìö Recursos

- [Spark Performance Tuning](https://spark.apache.org/docs/latest/sql-performance-tuning.html)
- [AWS EMR Cost Optimization](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html)
